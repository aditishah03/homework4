// preprocess.py

from pyspark.sql import SparkSession
from pyspark.sql import Row
import os

def parse_line(line):
    try:
        term_part, urls_part = line.split(",", 1)
        import re
        term = term_part.split(":")[1].strip()
        term = re.sub(r"[‘’“”\"]", "", term)

        url_clicks = urls_part.strip().split("~")
        records = []
        for uc in url_clicks:
            if ':' in uc:
                url, clicks = uc.split(":")
                records.append((term, url.strip(), int(clicks)))
        return records
    except Exception as e:
        print(f"Skipping malformed line: {line} | Error: {e}")
        return []

if __name__ == "__main__":
    # Start Spark session
    spark = SparkSession.builder \
        .appName("SearchLogPreprocessing") \
        .getOrCreate()

    rdd = spark.sparkContext.textFile("searchLog.csv")

    parsed_rdd = rdd.flatMap(parse_line)

    records = parsed_rdd.map(lambda x: Row(term=x[0], url=x[1], clicks=x[2]))
    df = spark.createDataFrame(records)

    output_dir = "processed_data"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    df.write.mode('overwrite').json(output_dir)

    print("Data successfully processed to 'processed_data/'")

    spark.stop()

// query_server.py

from flask import Flask, request, Response, jsonify
from pyspark.sql import SparkSession
import json

app = Flask(__name__)

spark = SparkSession.builder \
    .appName("QueryServer") \
    .getOrCreate()

df = spark.read.json("processed_data")
df.cache()

# Domain priority: .org > .edu > .com
def domain_priority(url):
    if url.endswith(".org"):
        return 1
    elif url.endswith(".edu"):
        return 2
    elif url.endswith(".com"):
        return 3
    else:
        return 4

@app.route('/results', methods=['POST'])
def results():
    term = request.json.get("term")

    filtered = df.filter(df.term == term)
    grouped = filtered.groupBy("url").sum("clicks")
    collected = grouped.collect()

    results = [(row["url"], int(row["sum(clicks)"])) for row in collected]

    # Sort only by clicks DESC
    results.sort(key=lambda x: x[1], reverse=True)

    # Build ordered JSON string manually
    result_dict = {"results": {url: clicks for url, clicks in results}}
    return Response(json.dumps(result_dict), mimetype='application/json')

@app.route('/trends', methods=['POST'])
def trends():
    term = request.json.get("term")
    filtered = df.filter(df.term == term)
    total_clicks = filtered.groupBy().sum("clicks").collect()[0][0]
    return jsonify({"clicks": int(total_clicks or 0)})

@app.route('/popularity', methods=['POST'])
def popularity():
    url = request.json.get("url")
    filtered = df.filter(df.url == url)
    total_clicks = filtered.groupBy().sum("clicks").collect()[0][0]
    return jsonify({"clicks": int(total_clicks or 0)})

@app.route('/getBestTerms', methods=['POST'])
def get_best_terms():
    website = request.json.get("website")
    filtered = df.filter(df.url == website)
    term_clicks_df = filtered.groupBy("term").sum("clicks")
    total_clicks = df.filter(df.url == website).groupBy().sum("clicks").collect()[0][0]
    if not total_clicks or total_clicks == 0:
        return jsonify({"best_terms": []})
    threshold = 0.05 * total_clicks
    best_terms = term_clicks_df.rdd \
        .filter(lambda row: row["sum(clicks)"] > threshold) \
        .map(lambda row: row["term"]).collect()
    return jsonify({"best_terms": best_terms})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)

