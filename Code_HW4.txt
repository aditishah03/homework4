// preprocess.py

from pyspark.sql import SparkSession
from pyspark.sql import Row
import os

def parse_line(line):
    try:
        term_part, urls_part = line.split(",", 1)
        term = term_part.split(":")[1].strip()
        url_clicks = urls_part.strip().split("~")
        records = []
        for uc in url_clicks:
            if ':' in uc:
                url, clicks = uc.split(":")
                records.append((term, url.strip(), int(clicks)))
        return records
    except Exception as e:
        print(f"Skipping malformed line: {line} | Error: {e}")
        return []

if __name__ == "__main__":
    # Start Spark session
    spark = SparkSession.builder \
        .appName("SearchLogPreprocessing") \
        .getOrCreate()

    # Read the log file
    rdd = spark.sparkContext.textFile("searchLog.csv")

    # Parse each line into (term, url, clicks)
    parsed_rdd = rdd.flatMap(parse_line)

    # Convert to DataFrame
    records = parsed_rdd.map(lambda x: Row(term=x[0], url=x[1], clicks=x[2]))
    df = spark.createDataFrame(records)

    # Save as JSON to processed_data/
    output_dir = "processed_data"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    df.write.mode('overwrite').json(output_dir)

    print("âœ… Data successfully processed to 'processed_data/'")

    spark.stop()

// query_server.py

from flask import Flask, request, jsonify
from pyspark.sql import SparkSession

app = Flask(__name__)

# Start SparkSession
spark = SparkSession.builder \
    .appName("QueryServer") \
    .getOrCreate()

# Load the processed data
df = spark.read.json("processed_data")
df.cache()

# Helper: domain priority sorter
def domain_priority(url):
    if url.endswith(".org"):
        return 1
    elif url.endswith(".edu"):
        return 2
    elif url.endswith(".com"):
        return 3
    else:
        return 4

@app.route('/results', methods=['POST'])
def results():
    term = request.json.get("term")
    filtered = df.filter(df.term == term)
    grouped = filtered.groupBy("url").sum("clicks")
    results = grouped.rdd.map(lambda row: (row["url"], row["sum(clicks)"])).collect()
    results.sort(key=lambda x: (-x[1], domain_priority(x[0])))
    return jsonify({"results": {url: clicks for url, clicks in results}})

@app.route('/trends', methods=['POST'])
def trends():
    term = request.json.get("term")
    filtered = df.filter(df.term == term)
    total_clicks = filtered.groupBy().sum("clicks").collect()[0][0]
    return jsonify({"clicks": int(total_clicks or 0)})

@app.route('/popularity', methods=['POST'])
def popularity():
    url = request.json.get("url")
    filtered = df.filter(df.url == url)
    total_clicks = filtered.groupBy().sum("clicks").collect()[0][0]
    return jsonify({"clicks": int(total_clicks or 0)})

@app.route('/getBestTerms', methods=['POST'])
def get_best_terms():
    website = request.json.get("website")
    filtered = df.filter(df.url == website)
    term_clicks_df = filtered.groupBy("term").sum("clicks")
    total_clicks = df.filter(df.url == website).groupBy().sum("clicks").collect()[0][0]
    if not total_clicks or total_clicks == 0:
        return jsonify({"best_terms": []})
    threshold = 0.05 * total_clicks
    best_terms = term_clicks_df.rdd \
        .filter(lambda row: row["sum(clicks)"] > threshold) \
        .map(lambda row: row["term"]).collect()
    return jsonify({"best_terms": best_terms})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
